---
title: "Linear Mixed Effects Models (LME) for Time Series Data "
author: "Kristopher Kyle"
date: "updated 01-28-2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

## Linear mixed effects models


### Description of sample data

This data comprises L2 English essays written over a two year period by nine middle-school aged Dutch children studying at an English/Dutch bilingual school in the Netherlands. Essays were collected three times a year (roughly every four months) over two academic years. Included in the dataset are holistic scores for each essay ("Score") and mean length of T-unit (MLT) values. In this tutorial, we will explore the relationship between MLT and time spent studying English, with the alternative hypothesis that MLT scores will increase as a function of time. For further reference, see Kyle (2016). In other words, we will be attempting to determine whether (and the degree to which) Dutch EFL middle school students write more words per T-unit (a T-unit is an independent clause and all connected depedent clauses) as a function of the time they spend studying English.

```{r}
mydata <- read.csv("data/RM_sample.csv", header = TRUE)
#First, we create a new variable that is the categorical version of Time
mydata$FTime <- factor(mydata$Time)
summary(mydata)
```

### Visualizing the data

First, we can look at the means at each time point. Overall, there appears to be a positive trend (i.e., more words per T-unit at later essay collection points), but this is not perfectly linear.

```{r}
library(ggplot2)
ggplot(data = mydata, aes(x = FTime, y = MLT, group = Time)) +
  geom_boxplot()
```

Then, we can get a clearer view by looking at individual trajectories.

```{r}
library(ggplot2)
ggplot(data = mydata, aes(x = FTime, y = MLT, group = Participant)) +
  geom_line(aes(color=Participant)) +
  geom_point(aes(color=Participant))
```
Sometimes, we get a clearer view of individual trajectories when we use facet wrap. As we can see, participants seem to be generally following an upward trend, but there are also non-linear trends (see EFL_6 and EFL 7 at week 3!).

```{r}
ggplot(data = mydata, aes(x = FTime, y = MLT, group = Participant)) +
  geom_line(aes(color=Participant)) +
  geom_point(aes(color=Participant)) +
  facet_wrap(~Participant)
```

### Conducting an LME
Linear mixed effects models allow us to account for both fixed effects (these are the variables we are most interested in, such as time spent studying English) and random effects, which are variables that may affect our results, but are not the main variables of interest. 

In this tutorial, we are primarily interested in time spent studying English (Time and/or FTime). However, many researchers have highlighted the idea that individuals take varying paths on their way to proficiency, so individual variation may affect our results. This is our random effect, because we want to account for individual variation, but it isn't our primary variable of interest.


#### Random intercepts

As noted above, our random effects are our participants (i.e., our main interest is not in intra-participant variation, but we still need to control for it). In the first model we will run, we will presume that all of our participants will follow similar trajectories, but may have different starting points (intercepts). In other words, the model will presume that participants will increase their MLT scores at approximately the same rate, but may have be at different writing proficiencies (at least with regard to MLT) at the beginning of the study. Also, first, we will run the analysis with time as a categorical variable (FTime), like we would with a repeated measures ANOVA. Then, we will run it as a continuous variable to show the difference. 

The most "appropriate" choice (treating Time as a factor or a continuos variable) will depend on our goals. If we want to see WHERE changes occurred (e.g., across particular time points), then we will want to treat time as a categorical variable. If we want to see the strength of the relationship (i.e., how strongly [and linearly] related Time and MLT scores are), then we will want to treat Ttime as a continous variable.

```{r}
library(lmerTest)
int_model1 <- lmer(MLT~FTime + (1 | Participant), data=mydata)
summary(int_model1)
```

Note that the "intercept" here presumes that FTime = 1, and all of the data points are in reference to this. So, from FTime 1 to FTime 2, there is a .6667 increase (which is not significant). Additionally, from FTime 1 to FTime 3, there is a 1.7767 increase (which is not significant). We don't get a significant change until we get to FTime 5. 

The Random Effects section above indicates that there is indeed variation across participants at each time point (the standard deviation is 1.102 words per T-unit).

We can also see the degree to which our estimates need to change for each participant (i.e., we can see our individualized random effects).

```{r}
ranef(int_model1)
```

Again, this is a random intercepts model, so the only changes we will see is in the intercept (i.e., starting point). All other estimates will be in relation to these revised intercepts. So, for example, at Time 1, EFL_1's estimated MLT score will be 9.6968 - 0.3623567 = 9.334443, while EFL_2's estimated MLT score will be 9.6968 + 1.2929820 = 10.98978. But remember, these are estimates created under the assumption that all participants will have the same slope (or rate of change), and we can see from looking at our plots that this estimate is decent for EFL_1, but rather poor for EFL_2.

The mismatch between estimated and actual scores is reflected in the effect size of the model, which we can obtain using the "MuMIn" package.

```{r}
library(MuMIn)
r.squaredGLMM(int_model1)
```

The "MuMIN" package gives us two R^2 values. The first, R2m (marginal r-squared), is the effect size without considering the random effects (i.e., where the model is built without regard to participant differences). The second, R^2c (conditional r-squared) is the effect size when the random effects are taken into account. Accordingly, the R^2c values are aways higher than the R^2m values (unless there are little/no random effects). 

The R^2m value here indicate that FTime accounts for 20.4% variance in MLT scores overall. The R^2c value indicates that participant variation + FTime together account for 35.5% of the variance in MLT scores.

**Getting Pairwise Comparisons**

Below, we use the package "emmeans" to get pairwise comparisons from our model (in case we want them). The emmeans packages is very flexible, so it is probably worthwhile to read the documentation on the package. As we can see below, the only significant pairwise difference (assuming an alpha level of .05) is between Time 1 and Time 5.

```{r}
library(emmeans)
int_model1.emm <- emmeans(int_model1, specs = pairwise~FTime)
summary(int_model1.emm)
```


**Time as a Continuous Variable**

We can also run our analysis with Time as a continuous variable (the distance between each Time value is roughly 4-months). In this case, we will be testing whether the line of best fit is a reasonable approximation of our data. Again, at this point, we are still working with a random intercepts model.

```{r}
int_model2 <- lmer(MLT~Time + (1 | Participant), data=mydata)
summary(int_model2) #get model summary
ranef(int_model2) #get slope adjustments per participant
r.squaredGLMM(int_model2) #get effect sizes
```

This indicates that Time is a significant predictor of MLT scores (p = .00027) with medium effects (R2^m = 0.191, R^2c = 0.355). Note below, we add the predicted scores for each participant to our dataframe using the "mutate" function of the package "dplyr". Then, we plot the predicted line (dashed) on top of the actual data. We see that each line has the same slope, but different intercepts.

```{r}
library(dplyr)
#add predicted values to dataframe
mydata <- mydata %>% mutate(int_model2_pred = predict(int_model2,re.form = ~ (1 | Participant)))

ggplot(mydata, aes(y=MLT, x=Time)) +
  facet_wrap(~ Participant) + 
  geom_point(aes(color=Participant), show.legend = FALSE) + 
  geom_line(aes(color=Participant), show.legend = FALSE) +
  geom_line(aes(y=int_model2_pred), linetype=2) +
  scale_y_continuous()
```

These results indicate that there is a significant, positive, medium relationship between Time and MLT. The results also indicate that there is a fairly high degree of variability across participants.

#### Random intercepts and random slopes

Above, we fit linear models with random intercepts, but fixed slopes. By doing so, we forced the model to assume that all individuals will follow the same slopes (i.e., increase/decrease the number of words per T-unit at the same rate over time). 

LMEs are quite flexible, however, and also allow us to fit more complicated models. For example, we can tell the model to adjust both the intercept (i.e., the starting MLT scores) and the slope (i.e., the rate and direction of change). More complicated models are often more difficult to interpret, but usually will account for more variance than simpler models. In general, we want to use models that optimize explanatory power and simplicity (more on this later).

Below, we will run a model with random intercepts AND random slopes, and then evaluate whether the more complicated model is reasonably better than the simpler one. We will almost always get a more accurate model when we add complexity, but the comlexity may not always be justified (e.g., it is a lot more difficult to explain a random intercepts and slopes model, and we only want to do so if it significantly increases our explanatory power). Note that we could treat Time either as a categorical variable or as a continuos variable. However, below we will only look at the continuous model.

```{r}
int_slope_model <- lmer(MLT~Time + (1 + Time | Participant), data=mydata)
summary(int_slope_model) #get model summary
```

As we see above, our results look almost identical to the previous model (int_model_2). The only difference is that we have statistics for one more random effect (Time) - our slope. Interestingly, once we added a random slope to the model, the variance in intercept vanished. In other words, the optimal model used the same intercept for all participants, but different slopes.

Below, we get by participant effects, which now include adjustments for slope AND intercept (though in this case the intercept is the same for all participants). We also see that our R^2m is almost identical, while our R^2c has increased slightly.

```{r}
ranef(int_slope_model)
r.squaredGLMM(int_slope_model)
```

When we plot our actual and predicted values, we now see that each participant has a slightly different slope. However, in this case, the differences are not extreme.

```{r}
library(dplyr)
mydata <- mydata %>% mutate(int_slope_model_pred = predict(int_slope_model,re.form = ~ (1 | Participant)))
ggplot(mydata, aes(y=MLT, x=Time)) +
  facet_wrap(~ Participant) + 
  geom_point(aes(color=Participant), show.legend = FALSE) + 
  geom_line(aes(color=Participant), show.legend = FALSE) +
  geom_line(aes(y=int_slope_model_pred), linetype=2) +
  scale_y_continuous()
```

To determine whether the more complicated model (random intercepts + slopes) is significantly better at modeling our data than the simpler one (random intercepts), we simply use the "anova" function, which indicates that there are indeed no significant differences between our models (p = 0.648), so we might as well use the simpler one.

```{r}
anova(int_model2,int_slope_model)
```

